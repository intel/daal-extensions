{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydaaltensorflow import DAALNet\n",
    "import pydaaltensorflow as pydaal\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary primitives and functions to create a simplified Convolutionl Neural Net (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variable(name, shape):\n",
    "  return tf.get_variable(name, shape, initializer=tf.random_normal_initializer(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, kernel, in_ch, out_ch, strides=[1, 1, 1, 1]):\n",
    "    W = get_variable(name='wc', shape=[kernel[0], kernel[1], in_ch, out_ch])\n",
    "    b = get_variable(name='bc', shape=[out_ch])\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    conv2d = tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "    conv2d = tf.nn.bias_add(conv2d, b)\n",
    "    return tf.nn.relu(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]): # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=ksize, strides=strides, padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgpool2d(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]): # AvgPool2D wrapper\n",
    "    return tf.nn.avg_pool(x, ksize=ksize, strides=strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(x, w_shape, b_shape):\n",
    "    W = get_variable(name='wd', shape=w_shape)\n",
    "    b = get_variable(name='bd', shape=b_shape)\n",
    "    # Fully connected layer with added biases\n",
    "    return tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a small CNN model which would be transformed to (Py)DAAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, n_classes):\n",
    "    # 1st Convolution Layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        conv1 = conv2d(x, [5, 5], 3, 32)\n",
    "        # Max Pooling (down-sampling)\n",
    "        conv1 = maxpool2d(conv1)\n",
    "\n",
    "    # 2nd Convolution Layer\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        conv2 = conv2d(conv1, [5, 5], 32, 64)\n",
    "        # Avg Pooling (down-sampling)\n",
    "        conv2 = avgpool2d(conv2)\n",
    "        conv2 = tf.reshape(conv2, [-1, 7*7*64])\n",
    "\n",
    "    # 1st Fully Connected Layer\n",
    "    with tf.variable_scope('full1') as scope:\n",
    "        full1 = fully_connected(conv2, [7*7*64, 1024], [1024])\n",
    "    \n",
    "    # Output, class prediction\n",
    "    with tf.variable_scope('full2') as scope:\n",
    "        full2 = fully_connected(full1, [1024, n_classes], [n_classes])\n",
    "\n",
    "    return full2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a proper TensorFlow environment and run and dump to the file the transformed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_case(data, checkpoint_dir):\n",
    "    # reshape data to TF format\n",
    "    data = np.transpose(data, (0, 2, 3, 1))\n",
    "\n",
    "    # Network Parameters\n",
    "    n_classes = 10\n",
    "\n",
    "    # reset the Graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(tf.float32, shape=data.shape)\n",
    "\n",
    "    # Construct model\n",
    "    pred = conv_net(x, n_classes)\n",
    "\n",
    "    # Transform to the Intel DAAL model\n",
    "    model = pydaal.transform(pred)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Provide a reference path to PyDAAL model\n",
    "    pydaal.dump_model(model, checkpoint_dir)\n",
    "\n",
    "    # Create a saver \n",
    "    saver = tf.train.Saver(tf.trainable_variables(), max_to_keep = 0)\n",
    "    \n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step = 0)\n",
    "\n",
    "        predictions  = sess.run(pred, feed_dict={x: data})\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some superficial data and run the above TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.random.randn(1, 3, 28, 28)/100\n",
    "tf_predictions = run_case(test_data, '/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a net from the dumped model (stored in the checkpoint directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = DAALNet().build('/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run forward pass again to obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net.predict(test_data) as predictions:\n",
    "    print('DAAL predictions: %s' % predictions)\n",
    "    print('TF predictions  : %s' % tf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
